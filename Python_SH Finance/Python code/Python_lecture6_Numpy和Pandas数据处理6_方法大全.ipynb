{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6讲 Numpy和Pandas数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >郭峰（Email：guofengsfi@163.com)   \n",
    "副教授、博士生导师  \n",
    "上海财经大学公共经济与管理学院 </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >本讲目录  \n",
    "6.1. Numpy基本应用      \n",
    "6.2. Pandas基本应用1  \n",
    "6.3. Pandas基本应用2   \n",
    "6.4. Pandas高级应用1  \n",
    "6.5. Pandas高级应用2   \n",
    "6.6. Pandas方法“大全”</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6.6. Pandas方法“大全”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建与读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>创建</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >可以通过一个list对象创建一个Series，pandas会默认创建整型索引</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series([1,3,5,8,10])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >dataframe的创建一般有两种方式，一是通过字典创建，二是分别指定数据、行索引和列索引创建</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>通过字典创建</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#构造DataFrame最常用的方式是字典+列表。语句先是字典外括，然后依次打出每一列标题及其对应的列值（此处一定要用列表）\n",
    "df1 = pd.DataFrame({'A':1.,\n",
    "                    'B':pd.Timestamp('20130102'),\n",
    "                    'C':pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D':np.array([3]*4, dtype='int32'),\n",
    "                    'E':pd.Categorical(['test','train','test','train']),\n",
    "                    'F':'foo'})\n",
    "#index表示行索引。如果创建时不指定index，系统会自动生成从0开始的索引。表头的每一个表示columns，表格内的具体参数值为values\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>分别指定数据、行索引和列索引</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "print(dates)\n",
    "df2 = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(np.random.randint(2,6,(5,4)))  #不指定索引和列名，系统默认自动编号\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>外部读取</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从外部读取数据，这是最重要的\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'D:/python/郭峰python讲义/数据与结果/06数据处理/'\n",
    "f = open(path+'beijingnews.csv',encoding = 'utf-8')\n",
    "df2 = pd.read_csv(f, header=0, sep=',')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>导出保存</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[['paper_name','date','title']][10:20]\n",
    "df2.to_csv(path+'beijing_test.csv',encoding='utf-8',index=False)  #存储位置为path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>快速认识数据</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看数据，掐头看尾，或者随机看看\n",
    "print(df2.head(10))  #如果想让每一个都显示出来，可以利用print()\n",
    "print(df2.tail())\n",
    "print(df2.sample())\n",
    "\n",
    "#格式查看\n",
    "print(df2.info()) #可以直接看到数据集的行列数，数据集的大小，每一列的数据类型，以及有多少条非空数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计信息概览\n",
    "print(df2.describe())  #快速计算数值数据的关键统计指标，比如平均数、中位数、标准差等等\n",
    "print(df2.shape)  #几行几列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理方式———增、删、选、改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>增加新列</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >增加一列，用df2['新列名']=新列值的形式，在原数据基础上赋值即可</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), columns=list('ABCD'))\n",
    "print(df)\n",
    "df['新增的列'] = range(1,len(df)+1)\n",
    "df['新增的列2']=['abc','bc','cd','addc','dd','efsgs']\n",
    "print(df.head())\n",
    "print(len(df))  #表示数据集有多少行，而不是列表中的字符串的长度\n",
    "print(df['新增的列2'].str.len()) #表述字段的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>空值填充</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({'a':[1, 2, 2, 5, 4],\n",
    "              'b':['ac','bbc','bbc','db','adc'],\n",
    "              'd':[1,3,3, np.nan,6]}   #np.nan表示空字段\n",
    "             )\n",
    "print(df2)\n",
    "df2['d']=df2['d'].fillna(';')  \n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>删除指定列或行</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >用drop函数指定删除对应的列，axis=1表示针对列的操作，inplace为True，表示直接在源数据上进行修改，否则源数据保持原样</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >删除数据的几种情况：https://www.cnblogs.com/cocowool/p/8421997.html</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('新增的列',axis=1, inplace=True)\n",
    "#df2.drop(['列1','列2','列3'],axis=1, inplace=True)  #删除多列\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>删除字段为空的行</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >dropna函数默认删除所有出现控制的行，即一行中任意一个字段为空，就会被删除。当只需要删除某一列的空行时，需要设置subset参数，例如dropna(subset=['city'])</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({'a':[1, 2, 2, 5, 4],\n",
    "              'b':['ac','bbc','bbc','db','adc'],\n",
    "              'd':[1,3,3, np.nan,6]}   #np.nan表示空字段\n",
    "             )\n",
    "print(df2)\n",
    "df2.dropna(subset=[\"d\"],inplace=True) \n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >删除字段重复的行</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.drop_duplicates(subset = '列名',keep='first')\n",
    "print(df2)\n",
    "df2.drop_duplicates()  #默认删除任何重复的字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >删除标题中含有以下字段的数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[~df2['b'].str.contains('bb')]\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>选择</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/python/郭峰python讲义/数据与结果/06数据处理/'\n",
    "f = open(path+'beijingnews.csv',encoding = 'utf-8')\n",
    "df2 = pd.read_csv(f, header=0, sep=',')\n",
    "\n",
    "#选取某一列。df2['列名']或df2.列名即可\n",
    "#print(df2['node_name'])   #单个列是series\n",
    "#print(df2.node_name)\n",
    "print(df2[['date','node_name','title']][0:10])  #一定要两个方括号，多列是dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择某列某行\n",
    "print(df2.node_name[3])\n",
    "print(df2['node_name'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='微软雅黑', size=3>通过loc和iloc选取符合特定条件的行列</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.iloc[where]   #按整数索引选取数据，选取单个行或行子集\n",
    "# df2.iloc[:,3]  #选取第3列\n",
    "# df2.iloc[4,3] #选取第四行第三列\n",
    "\n",
    "#行可以通过一定的条件获得\n",
    "#df2.loc[col]  #通过轴标签选取数据，选取单个行或行子集。对于单个行来说，iloc和loc是一样的\n",
    "print(df2.loc[df2['date'].isin(['2020-01-02']),'title'][0:20])  #选择2020年1月2日的title列的前二十行\n",
    "#print(df2.loc[df2['date']<'2020-01-02',['node_name','title']])  #选择日期2020年1月2日之前的node_name和title两列\n",
    "# df2.loc[:,'title']\n",
    "#df2.loc[2,'title']\n",
    "#df2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.loc[df2['content'].str.len()<200,:]['content'][0:10]) #显示内容字数小于200的前10行\n",
    "#print(df2.content.sample())  #随机选取content列的某行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face='微软雅黑', size=3>更改列名</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), columns=list('ABCD'))\n",
    "print(df)\n",
    "df.rename(columns={'D':'随机'}, inplace=True)\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用数据类型操作——字符串、数值型和日期型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>字符串操作 </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>字段内容显示设置  </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >有时为了对某列一内容进行编辑，但是由于内容较多，默认显示的字符较少，为了方便编辑，就需要显示全部内容 </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/python/郭峰python讲义/数据与结果/04数据处理/'\n",
    "f = open(path+'beijingnews.csv',encoding = 'utf-8')\n",
    "df2 = pd.read_csv(f, header=0, sep=',')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', -1) #设置value的显示最大值\n",
    "print(df2['content'][120])\n",
    "#pd.set_option('display.max_columns',None) #设置列显示不限制数量，如若限制，可将None设置成具体的数值\n",
    "#pd.set_option('display.max_rows', None)  #设置行显示限制数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>删除字段中指定字符  </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['content']=df2['content'].str.replace('[a-zA-Z</>&;=]','')  \n",
    "print(df2['content'][120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',50) #设置value的显示为50.由于后面无需在显示全部内容，所以将显示内容最大设置为50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>数值型操作 </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数值型。数值型数据，常见的操作是计算，分为单个值运算，长度相等列的运算\n",
    "#源数据是没有数据类的，为了试验，我们新增1列数值数据\n",
    "df = pd.DataFrame(np.random.randint(1,10,(4,6)), columns=list('ABCDEF'))\n",
    "print(df)\n",
    "df['F']=df['F']+1000\n",
    "print(df)\n",
    "df['E']=2\n",
    "print(df)\n",
    "df['积']=df['E']*df['F']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>日期类型数据操作 </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,10,(4,6)), columns=list('ABCDEF'))\n",
    "print(df)\n",
    "df['日期']='2020-4-30' #新增一列日期，但是这只是字符串格式的\n",
    "df.head()\n",
    "df['日期']=pd.to_datetime(df['日期'])  #\n",
    "df['日期'].head()\n",
    "df['距离起始日期']=pd.to_datetime('2020-5-30')-pd.to_datetime(df['日期'])  #可以对日期进行计算\n",
    "print(df)\n",
    "#详细资料参考：https://blog.csdn.net/qq_22238533/article/details/70050748"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据拼接之concat、join、merge、append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" > concat和append可以实现的是表间的‘拼接’,而merge和join则实现的是表间‘合并’。区别在于是否基于‘键’来进行合并。如果只是简单地‘堆砌’,则用concat和append比较合适，而如果遇到关联表，需要根据‘键’来合并，则用merge和join。  \n",
    "concat和merge是pandas的属性，所以调用的时候应该写成pd.concat()或者pd.merge();而append和join是对DataFrame的方法，所以调用的时候写成df.append()或者df.join()。  \n",
    "append只能实现拼接，从这个观点来看，concat的功能更加强大。理论上append可以完成的操作concat都可以完成，只需要更改相应的参数即可。  \n",
    "类似于append之于concat，join可以完成的工作merge也都可以完成，因此merge更加强大。  \n",
    "append和join存在的意义在于简洁和易用。  \n",
    "最关键地， concat后面对于df的参数形式objs，这个objs可以是一个列表或者集合，里面可以有很多df；而merge后面跟的参数形式是left和right，只有两个df。因此，concat其实可以快速实现多表的拼接，而merge只能实现两表的合并。 </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.csdn.net/weixin_42782150/article/details/89546357?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase\n",
    "#链接中才说明concat时有误。默认是列拼接\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A':['A0','A1','A2','A3'],'B':['B0','B1','B2','B3'],\n",
    "                   'C':['C0','C1','C2','C3'],'D':['D0','D1','D2','D3']}, index=[0, 1, 2, 3])\n",
    "df2 = pd.DataFrame({'A':['A4','A5','A6','A7'], 'B':['B4','B5','B6','B7'],\n",
    "                   'C':['C4','C5','C6','C7'], 'D':['D4','D5','D6','D7']}, index=[4, 5,6,7])\n",
    "df3 = pd.DataFrame({'A':['A8','A9','A10','A11'],'B':['B8','B9','B10','B11'],\n",
    "                   'C':['C8','C9','C10','C11'], 'D':['D8','D9','D10','D11']},\n",
    "                  index=[8, 9, 10, 11])\n",
    "df4 = pd.DataFrame({'B':['B2','B3','B6','B7'], 'D':['D2','D3','D6','D7'],\n",
    "                  'F':['F2','F3','F6','F7']}, index=[2,3,6,7])\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(df3)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>concat </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >语法格式：  \n",
    "pandas.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None,verify_integrity=False, sort=None, copy=True)  \n",
    "abjs:series,dataframe或者panel对象构成的序列  \n",
    "axis：知名连接的轴向，{0：列columns; 1：行index}，默认为0  \n",
    "join：指定连接方式，{’inner‘（交集），’outer'(并集)},默认为outer  \n",
    "join_axes:自定义的索引。指明用其他n-1条轴的索引进行拼接，而非默认的join=inner或outer方式拼接。  \n",
    "keys:创建层次化索引。可以是任意值的列表或数组、元组数据、数组列表（如果将level设置成多级数组的话）  \n",
    "ignore_index=True:重建索引  \n",
    "join_axes： </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col=pd.concat([df1, df2, df3])   #concat默认列拼接\n",
    "print(df_col)\n",
    "df_row=pd.concat([df1, df2, df3], axis=1)  #当axis=1时，concat为行拼接\n",
    "print(df_row)\n",
    "df_param=pd.concat([df1,df2,df3], keys=['x','y','z'])  #使用参数key为每个数据集指定块标记\n",
    "print(df_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#列名（columns）和行索引（index）均有重复的实现列/行拼接（默认‘join=outer’）：）\n",
    "#使用concat()实现列拼接，没有的列用NaN填充，默认是outer，即并集\n",
    "result1 = pd.concat([df1, df4])\n",
    "print(result1)\n",
    "#使用concat()实现行拼接，没有的行用NaN填充\n",
    "result2 = pd.concat([df1, df4], axis=1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#列名（columns）和行索引（index）均有重复的表df1、df4实现行/列拼接（设置‘join=inner'）\n",
    "#concat修改join='inner'，只保留重复列索引和列拼接，即行列索引的交集\n",
    "result3=pd.concat([df1,df4], join='inner')  \n",
    "print(result3)\n",
    "#concat修改为join='innder'，只保留重复行索引的行拼接\n",
    "result4=pd.concat([df1,df4],axis=1,join='inner')\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>merge</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >语法格式：  \n",
    "DataFrame.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False,sort=False, suffixes=('_x','_y'), copy=True, indicator=False, validate=None)  \n",
    "merge()只能完成两张表的连接，若有三个及三个以上的表，需不断两个合并来实现）\n",
    "\n",
    "参数说明：  \n",
    "left和right:两个不同的DataFrame或Series  \n",
    "how:连接方式，有inner、left、right、outer，默认为inner  \n",
    "on：用于连接的列索引名称，必须同时存在于左右两个DataFrame中，默认是两个DataFrame列名的交集作为连接键，若要实现多键连接，‘on’参数后传入多键列表即可。  \n",
    "left_on：左侧DataFrame中用于连接键的列名，这个参数在左右列不同但代表的含义相同时非常有用  \n",
    "right_on:右侧DataFrame中用于连接键的列名  \n",
    "left_index：使用左侧的DataFrame中的行索引作为连接键（但是这种情况下最好用join）  \n",
    "right_index:使用右侧DataFrame中的行索引作为连接键（但是这种情况下最好使用join）  \n",
    "sort:默认为False，将合并的数据进行排序，设置为false可以提高幸能  \n",
    "suffixes:字符串值组成的元组，用于指定当左右DataFrame存在相同列名时在列名后面附加的后缀名称，默认为（'_x', '_y')  \n",
    "copy:默认为True，总是将数据复制到数据结构中，设置为False可以提高性能  \n",
    "indicator:显示合并数据的来源情况</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#两张表df1和df2的列名有重叠，且重叠列的内容完全相同，直接用pd.merge(df1,df2)，即合并为交集部分\n",
    "df1=pd.DataFrame(np.arange(12).reshape(3,4), columns=['a','b','c','d'])\n",
    "print(df1)\n",
    "df2=pd.DataFrame({'b':[1, 5], 'd':[3, 7], 'a':[0, 4]})\n",
    "print(df2)\n",
    "print(pd.merge(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#两张表df1和df2的列名有重叠，但重叠列的内容完全不同，需使用pd.merge(df1,df2,letf_index=True, right_index=True, how='letf')\n",
    "#如果直接用pd.merge(df1,df2)，将会得到一张空表，故必须指定行索引参数left_index，right_index,这种情况下最好使用join实现。\n",
    "df1=pd.DataFrame(np.arange(12).reshape(3,4), columns=['a','b','c','d'])\n",
    "print(df1)\n",
    "df2=pd.DataFrame({'b':[15,6],'d':[1,11],'a':[0,6]})\n",
    "print(df2)\n",
    "\n",
    "pd.merge(df1, df2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>join</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >语法格式：  \n",
    "DataFrame.join(other, on=None, how='left', lsuffix=' ', rsuffix=' ', sort=False)    \n",
    "核心功能：无重复列名的两个表df1和df2基于行索引进行行列拼接，直接使用df1.join(df2)即可，无需添加任何参数，合并表的行数与left表相同，列数为Left表+right表的列数之和。  \n",
    "结果仅保留left表和right表中行索引相同的行，对列不做任何处理。如果两个表有重复的列名，需指定lsuffix, rsuffix参数  \n",
    "利用join也可基于列索引进行行拼接，需借助参数'on'。  \n",
    "无重复列名的两个表df1和df3基于行索引，进行列拼接，直接使用df1.join(df2)即可  \n",
    "有重复列名的两个表df1和df2（即使内容没有重复）基于行索引，进行列拼接，使用df1.join(df2)时需要指定lsuffix，rsuffix参数，即：df1.join(df2,  \n",
    "lsuffix='_1',rsuffix='_r'),否则会报错。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(12).reshape(3,4), columns=['a','b','c','d'])\n",
    "print(df1)\n",
    "df2=pd.DataFrame({'b':[15,6], 'd':[1, 11], 'a':[0, 6]})\n",
    "print(df2)\n",
    "df1.join(df2, lsuffix='_1',rsuffix='_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#列名不同，列内容有相同的两个表df1和df2基于行索引，进行列拼接，使用left.join(r.set_index(key of r), on='key of 1')\n",
    "left=pd.DataFrame({'key1':['foo','bar1'], 'lval':[1,2]})\n",
    "print(left)\n",
    "right = pd.DataFrame({'key2':['foo','bar'], 'rval':[4,5]})\n",
    "print(right)\n",
    "\n",
    "left.join(right.set_index('key2'), on='key1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>merge</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >语法格式：  \n",
    "DataFame.append(other, ignore_index=False, verify_integrity=False, sort=None)  \n",
    "核心功能：append是concat的间略形式,只不过只能在axis=0上进行合并。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(12).reshape(3,4), columns=['a','b','c','d'])\n",
    "print(df1)\n",
    "df2=pd.DataFrame({'b':[15,6], 'd':[1, 11], 'a':[0, 6]})\n",
    "print(df2)\n",
    "print(df1.append(df2))\n",
    "print(df1.append(df2, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用函数之map()、apply()、与applymap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- map()：作用于单独一列（Series）的每个元素中  \n",
    "- apply():作用于Series或者DataFrame的行或列中  \n",
    "- applymap():作用于DataFrame的所有元素中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考网站：https://mp.weixin.qq.com/s?src=11&timestamp=1593647581&ver=2435&signature=b00sCEH4x78PYKqQsHCLWJ6BvvTGjJD5j624Dy*WinyI14DRuhJ5yo59pv3Sx1S41xHFaMYuSRb2Gf0tyI9MiY4SbM7zG4FDvfWF074ksRjged3eMFkmzAVl1Mg5Q9H1&new=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>map()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "gender=['男','女']\n",
    "skin=['white','black','yellow']\n",
    "date=['2020-01-02','2020-01-10','2020-01-15','2020-01-20','2020-01-31']\n",
    "smoker=[True, False]\n",
    "\n",
    "data=pd.DataFrame({\n",
    "    'height':np.random.randint(150,170,50),\n",
    "    'weight':np.random.randint(40,90,50),\n",
    "    'gender':[gender[x] for x in np.random.randint(0,2,50)],\n",
    "    'smoker':[smoker[x] for x in np.random.randint(0,2,50)],\n",
    "    'age':np.random.randint(15,90,50),\n",
    "    'skin':[skin[x] for x in np.random.randint(0,len(skin),50)],\n",
    "    'date':[date[x] for x in np.random.randint(0, len(date), 50)],\n",
    "})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>字典映射 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >将gender列的男、女转换为M、F的新列</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_mf={'女':'F','男':'M'}\n",
    "data['gender_mf'] = data.gender.map(gender_mf)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>lambda函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender_mf_lam'] = data.gender.map(lambda x: 'M' if x=='男' else 'F')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>自定义函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_to_mf(x):\n",
    "    return 'F' if x=='女' else 'M'\n",
    "\n",
    "data['gender_to_mf'] = data.gender.map(gender_to_mf)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>apply</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply()方法的作用原理和map()方法类似，区别在于apply()能够传入功能更为复杂的函数。 先假设要根据性别调整用户的体重（weight），则需要根据条件对其进行调整（加上或减去一个值），由于这个加上或减去的值未知，故在定义函数时，需要增加两个参数，此时用map()的方法操作不了（map()的函数只能接收一个参数），此时apply()方法则可以解决这个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weight(x, args_f, args_m):\n",
    "    if x=='女':\n",
    "        return args_f\n",
    "    else:\n",
    "        return args_m\n",
    "\n",
    "data['weight_new']=data['weight']+data['gender'].apply(apply_weight,args=(-5, 8))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总而言之，对于Series而言，map可以解决大多数的数据处理需求，但如果需要使用较为复杂的函数，则需要用到apply方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply()用法 apply()传入的主要参数都是接受输入返回输出，但相较于map()针对单列Series进行处理，一条apply()语句可以对单列或多列进行运算，覆盖非常多的使用场景，该函数如下： DataFrame.apply(func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最重要的参数是传入函数，传入函数会对DataFrame的每一行（index）或每一列（column）进行操作，然后返回每一个index或column对应的值，再将这些行（或者列）以及其对应的返回值重新组合成一个DataFrame的对象，然后作为整个apply方法的返回值返回。值于传入函数具体是对每一行还是每一列进行操作，取决于apply()传入的axis参数，默认axis=0表示对每一列进行操作，axis=1表示对每一行进行操作。因此，apply方法最重要两个参数是传入函数func和axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>单列操作</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender_apply'] = data.gender.apply(lambda x: 'M' if x=='男' else 'F')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>输入多列</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理多个值时要给apply添加参数axis=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statement(height, weight, gender, age):\n",
    "    return '身高{}厘米，体重{}公斤，性别{}，年龄{}岁。'.format(height, weight,gender, age)\n",
    "data['desc'] = data.apply(lambda row: descriptive_statement(row['height'], row['weight'], row['gender'], row['age']),axis = 1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>applymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "applymap()是与map方法相对应的专属于DataFrame对象的方法，类似map()方法传入函数、字典等，传入对应的输出结果，不同的是applymap()将传入的函数等作用于整个数据框中每一个位置的元素，因此其返回结果的形状与原数据框一致，譬如下面的简单示例，我们把婴儿姓名数据中所有字符型数据小型化处理，对其他类型则原样返回："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_all_string(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.lower()\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "data.applymap(lower_all_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聚合分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>goupby()分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在pandas中对数据框进行分组使用到groupby()方法，其主要使用到的参数为by,这个参数用于传入分组依据的变量名称，当变量为1个时传入名称字符即可，当为多个时传入这些变量名称列表，DataFrame对象通过groupby()之后返回一个生成器，需要将其列表话才能得到需要的分组后的子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data.groupby(by=['gender','skin']) #按照性别和肤色进行数据分组\n",
    "#type(groups)  #此时是生成器，需要用列表解析提取分组结果\n",
    "print(list(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by=['gender', 'skin'])['age'].max()  #提取age列后直接调用max()方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意这里的year、gender列是以索引的形式存在的，想要把它们还原回数据框，使用reset_index(drop=False)即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by=['gender','skin'])['age'].max().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\", size=3>利用agg()进行更灵活的聚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agg(即aggregate), 聚合在pandas中可以利用agg()对Series、DataFrame以及groupby()后的结果进行聚合，其传入的参数为字典，键位变量名，值为对应的聚合函数字符串，譬如{'v1':['sum','mean'], 'v2':['median','max','min']}就代表对数据框中的v1列进行求和、均值操作，对v2列进行中位数、最大值、最小值操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚合Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在对Series进行聚合时，因为只有1列，所以不适用字典的形式传递参数，直接传入函数名列表即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['weight'].agg(['min','max','median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚合DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对DataFrame进行聚合时因为有多列，所以要使用字典的方式传入聚合方案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.agg({'height': ['max', 'min'], 'weight':['mean', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚合groupby()结果\n",
    "对DataFrame进行聚合时因为有多列，所以要使用字典的方式传入聚合方案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['gender', 'smoker']).agg({'height':['min','max','median']}).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>本讲结束</font>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
