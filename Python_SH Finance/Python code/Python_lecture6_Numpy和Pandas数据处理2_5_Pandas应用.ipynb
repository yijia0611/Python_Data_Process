{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6讲 Numpy和Pandas数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >郭峰（Email：guofengsfi@163.com)   \n",
    "副教授、博士生导师  \n",
    "上海财经大学公共经济与管理学院 </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >本讲目录  \n",
    "6.1. Numpy基本应用      \n",
    "6.2. Pandas基本应用1  \n",
    "6.3. Pandas基本应用2   \n",
    "6.4. Pandas高级应用1  \n",
    "6.5. Pandas高级应用2   \n",
    "6.6. Pandas方法“大全”</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.Pandas基本应用1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>Pandas基本介绍</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >pandas概念的基本介绍：http://m.sohu.com/a/158827610_693397  \n",
    "pandas里定义的数据类型： （1）object字符值；（2）int整型；（3）float浮点型；（4）datatime时间值；（5）bool布尔  \n",
    "pandas数据清洗参考资料：https://www.cnblogs.com/stream886/p/6021743.html  \n",
    "https://blog.csdn.net/claroja/article/details/65661826</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >在6.2-6.5讲中，我们主要以中国知网数据为例，讲解pandas数据整理的基本操作,涉及数据清洗、增加、删除、合并、正则表达式等等。\n",
    "数据源：CSSCI期刊，核心板、拓展版、辑刊和北大核心，1998-2018年，370余万原始爬虫记录（用于演示1万条）</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>数据导入</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path='D:/python/郭峰Python讲义/数据与结果/06数据处理/cssci/'\n",
    "\n",
    "#数据导入，其他格式数据导入：https://www.cnblogs.com/OliverQin/p/8966321.html\n",
    "f = open(path+\"cssci_org_test.csv\",encoding='utf8')\n",
    "papers= pd.read_csv(f,header=0,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>数据特征查看</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#作为示例，输出CSV文件的前5行和最后5行，这是pandas默认的输出5行，可以根据需要自己设定输出几行的值\n",
    "print(papers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>另一种数据查看方法</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.head(3)\n",
    "papers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers[['title']][0:3])\n",
    "#print(papers[['title','author']][0:3])\n",
    "#papers[['title','author']][0:3]\n",
    "papers['title'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers.shape) #数据大小，行*列\n",
    "print(\"原始爬虫数量:\"+str(len(papers))) #查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单个数据的展示\n",
    "print(\"页码最大值：\",papers['page_num'].max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#描述性统计\n",
    "print(papers.describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>其他常见统计</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(papers.shape)  # 输出dataframe有多少行、多少列。\n",
    "#print(papers.shape[1])  # 取行数量，相应的列数量就是df.shape[1]\n",
    "#print(papers.columns) # 顺序输出每一列的名字，演示如何for语句遍历。\n",
    "#print(papers.index) # 顺序输出每一行的名字，可以for语句遍历。\n",
    "#print(papers.dtypes) # 数据每一列的类型不一样，比如数字、字符串、日期等。该方法输出每一列变量类型\n",
    "#print(papers.head(3))  # 看前3行的数据，默认是5。与自然语言很接近\n",
    "#print(papers.tail(3))  # 看最后3行的数据，默认是5。\n",
    "print(papers.sample(3))  # 随机抽取3行，想要去固定比例的话，可以用frac参数\n",
    "#print(papers.describe())  # 非常方便的函数，对每一列数据有直观感受；只会对数字类型的列有效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers['page_num'].mean())  # 求一整列的均值，返回一个数。会自动排除空值。\n",
    "print(papers[['page_num']].mean())  # 求两列的均值，返回两个数，Series\n",
    "print(papers[['page_num', 'cited']])\n",
    "print(papers[['page_num', 'cited']].mean(axis=1))  # 求两列的均值，返回DataFrame。axis=0或者1要搞清楚。\n",
    "#axis=1，代表对整几列进行操作。axis=0（默认）代表对几行进行操作。实际中弄混很正常，到时候试一下就知道了。\n",
    "print(papers['page_num'].max())  # 最大值\n",
    "print(papers['page_num'].min())  # 最小值\n",
    "print(papers['page_num'].std())  # 标准差\n",
    "print(papers['page_num'].count())  # 非空的数据的数量\n",
    "print(papers['page_num'].median())  # 中位数\n",
    "print(papers['page_num'].quantile(0.25))  # 25%分位数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>删除重复数据</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >删除爬虫时的重复值，以标题、期刊名和作者同时重复为准。删除数据参考：https://blog.csdn.net/qq_28811329/article/details/7996251</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.drop_duplicates(subset=['title','author','mag_name'],keep='first',inplace=True) \n",
    "print(\"删除重复爬虫后数量:\"+str(len(papers))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >凡是会对原数组作出修改并返回一个新数组的，往往都有一个 inplace可选参数。如果手动设定为True（默认为False），那么原数组直接就被替换。而采用inplace=False之后，原数组名对应的内存值并不改变，需要将新的结果赋给一个新的数组</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>删除（保留）特定的样本</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >删除数据的几种情况：https://www.cnblogs.com/cocowool/p/8421997.html </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除空值\n",
    "papers.dropna(subset=[\"author\"],inplace=True)  #删除作者为空的样本\n",
    "#删除空值的另一种方式，将df中A列所有空值赋值为'null'，然后再删除\n",
    "#papers['author']=papers['author'].fillna(';') \n",
    "#papers=papers[~papers['author'].isin(['null'])]\n",
    "print(\"删除作者为空后数量:\"+str(len(papers))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除非论文文章：删除标题中还有以下字段的数据\n",
    "papers=papers[~papers['title'].str.contains('卷首语')]\n",
    "papers=papers[~papers['title'].str.contains('寄语')]\n",
    "papers=papers[~papers['title'].str.contains('发刊词')]\n",
    "papers=papers[~papers['title'].str.contains('序言')]\n",
    "papers=papers[~papers['title'].str.contains('简讯')]\n",
    "papers=papers[~papers['title'].str.contains('会讯')]\n",
    "papers=papers[~papers['title'].str.contains('会议简述')]\n",
    "papers=papers[~papers['title'].str.contains('会议综述')]\n",
    "papers=papers[~papers['title'].str.contains('会议纪实')]\n",
    "papers=papers[~papers['title'].str.contains('研讨会')]\n",
    "papers=papers[~papers['title'].str.contains('名单')]\n",
    "papers=papers[~papers['title'].str.contains('纪要')]\n",
    "papers=papers[~papers['title'].str.contains('诞辰')]\n",
    "papers=papers[~papers['title'].str.contains('悼词')]\n",
    "papers=papers[~papers['title'].str.contains('评奖')]\n",
    "papers=papers[~papers['title'].str.contains('目录')]\n",
    "papers=papers[~papers['title'].str.contains('启事')]\n",
    "papers=papers[~papers['title'].str.contains('广告')]\n",
    "papers=papers[~papers['title'].str.contains('公告')]\n",
    "print(\"删除非论文后数量:\"+str(len(papers))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.3：把上述删除非论文的程序修改为一个循环    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除异常期刊名称【演示数据中不存在这些期刊】\n",
    "papers=papers[~papers['mag_name'].str.contains('China & World Economy')]\n",
    "papers=papers[~papers['mag_name'].str.contains('China Legal Science')]\n",
    "papers=papers[~papers['mag_name'].str.contains('湘潭大学社会科学学报研究生论丛')]\n",
    "papers=papers[~papers['mag_name'].str.contains('湘潭大学学报研究生论丛')]\n",
    "papers=papers[~papers['mag_name'].str.contains('中央民族大学学报自然科学版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('商情财经研究')]\n",
    "papers=papers[~papers['mag_name'].str.contains('科技广场管理科学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('云南经济管理干部学院学报')]\n",
    "papers=papers[~papers['mag_name'].str.contains('山东农业农村经济')]\n",
    "papers=papers[~papers['mag_name'].str.contains('中国电视纪录')]\n",
    "papers=papers[~papers['mag_name'].str.contains('公民与法法学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('China International Studies')]\n",
    "papers=papers[~papers['mag_name'].str.contains('新课程研究教育研究与实验')]\n",
    "papers=papers[~papers['mag_name'].str.contains('北京联合大学学报自然科学版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('北京联合大学学报教育教学研究专辑')]\n",
    "papers=papers[~papers['mag_name'].str.contains('山西财经大学学报高等教育版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('Chinese Journal of Library and Information Science')]\n",
    "papers=papers[~papers['mag_name'].str.contains('上海包装')]\n",
    "papers=papers[~papers['mag_name'].str.contains('药物评价研究')]\n",
    "papers=papers[~papers['mag_name'].str.contains('智能系统学报')]\n",
    "papers=papers[~papers['mag_name'].str.contains('中国战略新兴产业')]\n",
    "papers=papers[~papers['mag_name'].str.contains('吉林大学学报工学版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('商丘职业技术学院学报')]\n",
    "papers=papers[~papers['mag_name'].str.contains('食品科学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('玉米科学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('电脑知识与技术学术交流')]\n",
    "print(\"删除异常期刊后数量:\"+str(len(papers))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.Pandas基本应用2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font face=\"微软雅黑\" size=3>变量操作</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除标题异常样本\n",
    "papers[\"tlength\"]=papers['title'].str.len()  #标题长度，不能是papers[\"tlength\"]=len(papers['title'])\n",
    "papers[\"tlength2\"]=len(papers['title'])\n",
    "print(papers.tlength[0:10])\n",
    "print(papers.tlength2[0:10])\n",
    "print(papers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers=papers[papers['tlength'] <100]  #删除标题长度大于等于100的异常值\n",
    "papers=papers[papers['tlength'] >2]  #删除标题长度小于等于2的异常值\n",
    "print(\"标题剔除后数量:\"+str(len(papers))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除页码长度异常样本\n",
    "papers=papers[(papers['page_num'] >0) & (papers['page_num'] <50)]\n",
    "print(\"页码异常剔除后数量:\"+str(len(papers))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#期刊名称整理\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"(\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\")\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"（\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"）\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"\\n\",\"\")  #部分期刊名称存在换行的异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不规范期刊名称替换\n",
    "fmag_name= open(path+\"mag_name_adj.csv\",encoding='utf8')\n",
    "mag_name= pd.read_csv(fmag_name,header=0,sep=',')\n",
    "print(mag_name.head())\n",
    "for i in range(0,len(mag_name)):\n",
    "    papers[\"mag_name\"] =papers['mag_name'].str.replace(str(mag_name.mag_name_ord[i]),str(mag_name.mag_name_new[i]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除作者异常样本\n",
    "papers.dropna(subset=[\"author\"],inplace=True)  #删除作者为空的样本\n",
    "papers=papers[~papers['author'].str.contains('编辑部')]   #删除作者信息中包含“编辑部”的样本。\n",
    "print(papers['author'][0:5])\n",
    "papers[\"aunum\"] =papers['author'].str.count(\";\")+1  #作者人数计算\n",
    "papers=papers[papers['aunum'] <20]    #删除作者数量大于等于20的样本\n",
    "print(\"作者异常剔除后数量:\"+str(len(papers))) #查看行*列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##分类号处理，只保留第一个字母\n",
    "print(papers[\"class_num\"] [0:10])\n",
    "papers[\"class_num\"] =papers['class_num'].str.replace(\"分类号：\",\"\")\n",
    "papers['class_num']=papers['class_num'].str.replace('(\\d+)',\"\")\n",
    "papers['class_num']=papers['class_num'].str.replace('.',\"\") \n",
    "papers['class_num']=papers['class_num'].str.replace('+',\"\")\n",
    "papers['class_num']=papers['class_num'].str.replace('-',\"\")\n",
    "print(papers[\"class_num\"].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算主题模型时，需要将标题、关键词和摘要合并\n",
    "papers['keyword']=papers['keyword'].fillna(\";\")\n",
    "papers['content']=papers['title']+\"#\"+papers['keyword']+\"#\"+papers['abstract']\n",
    "papers=papers[papers['content'].str.len()>100]   #将标题+关键词+摘要少于等于100字的样本删除\n",
    "print(\"标题+关键词+摘要少于100字的样本删除后数量:\"+str(len(papers))) #查看行*列数\n",
    "print(papers.shape)#查看行*列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同类型数据相加:\n",
    "papers['content']=papers['title']+\"#\"+papers['page_num']+\"#\"+papers['abstract']\n",
    "papers=papers[papers['content'].str.len()>100]   #将标题+关键词+摘要少于100字的样本删除\n",
    "print(\"标题+关键词+摘要少于100字的样本删除后数量:\"+str(len(papers))) #查看行*列数\n",
    "print(papers.shape)#查看行*列数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>时间梳理整理：文本方法</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers['year_period'])\n",
    "papers['year_period']=papers['year_period'].str[0:10]  #部分样本存在“2017-12-15 14：55”这样的year_period\n",
    "#papers['year_period']=papers['year_period'][0:10]  #如果是这样，则代表只要这个变量的前10行。。。\n",
    "papers['year_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['year']=papers['year_period'].str[0:4]\n",
    "papers['month']=papers['year_period'].str[5:7]\n",
    "papers=papers[papers['year'].str.len()>0]  #部分样本日期存在错误\n",
    "#年和月数据都转换成整数\n",
    "papers['year']=papers['year'].astype(\"int\")\n",
    "papers['month']=papers['month'].astype(\"int\")\n",
    "print(papers['year'].head())\n",
    "#以下语法对部分样本可用，现在全样本存在错误，日期格式存在非法字符\n",
    "#papers['date_time'] = pd.to_datetime(papers['year_period'])\n",
    "#papers['year']=papers['date_time'].dt.year\n",
    "#papers['month']=papers['date_time'].dt.month\n",
    "papers=papers[papers[\"year\"]<2019]\n",
    "papers=papers[papers[\"year\"]>1997]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.4：将之前演员数据读成数据框格式，并参考上述方法，进行简单的一些处理\n",
    "#文件夹：path='D:/python/郭峰Python讲义/数据与结果/'\n",
    "#文件名称：actors.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.5：对论文的关键词进行“清洗”，并计算每篇论文的关键词个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>日期数据处理</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['date_time'] = pd.to_datetime(papers['year_period'])\n",
    "print(papers['date_time'][0:10])\n",
    "papers['year']=papers['date_time'].dt.year\n",
    "papers['month']=papers['date_time'].dt.month\n",
    "print(papers.year[0:5])\n",
    "print(papers.month[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['week']=papers['date_time'].dt.week\n",
    "papers['week'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#发表日期精确到月\n",
    "papers['ym']=papers['year'].astype('str')+'-'+papers['month'].astype('str')+'-'+'01'\n",
    "print(papers['ym'].head())\n",
    "papers['ym']=pd.to_datetime(papers['ym']) \n",
    "print(papers['ym'][0:5])\n",
    "#print(\"年份异常剔除后数量:\"+str(len(papers))) #查看行*列数1541039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.6：通过网络检索寻找方法，在上述日期格式数据上增加10天。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Pandas高级应用1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>样本分列</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一作者识别，这个涉及到pandas分列\n",
    "#https://www.jianshu.com/p/4a2ecf65e3ea\n",
    "print(papers['author'][0:5])\n",
    "papers['author_first']=papers['author'].str.split(';')\n",
    "print(papers['author'][0:10])\n",
    "print(papers.author_first[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers['author_first'].str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['author_first']=papers['author'].str.split(';',expand=True)[0]\n",
    "print(papers.author_first[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合作者提取，只以第一个“；”来分割，并保留第二个，从而得到第一作者之外的所有合作者\n",
    "papers['coauthor']=papers['author'].str.split(';',n=1,expand=True)[1]  \n",
    "print(papers['coauthor'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一行变多行,这个应用较少\n",
    "author=papers['author'].str.split(';', expand=True).stack()\n",
    "print(author[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.7：通过变量分列操作，提取每篇论文的前3个（不超过3个）关键词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>变量追加</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >参考资料：https://blog.csdn.net/stevenkwong/article/details/52528616</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers.shape)\n",
    "path='D:/python/郭峰Python讲义/数据与结果/06数据处理/cssci/'\n",
    "f2 = open(path+\"cssci_org_test.csv\",encoding='utf8')\n",
    "papers2= pd.read_csv(f2,header=0,sep=',')\n",
    "print(papers2.shape)\n",
    "papers_new= papers.append(papers2)\n",
    "print(papers_new.shape)\n",
    "papers_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>变量合并</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#期刊-主办单位匹配\n",
    "#pandas merge方法：https://blog.csdn.net/Darkman_EX/article/details/80726166\n",
    "fmag= open(path+\"mag_unit.csv\",encoding='utf8')\n",
    "fmag= pd.read_csv(fmag,header=0,sep=',')\n",
    "print(fmag.shape)\n",
    "print(fmag.head())\n",
    "\n",
    "papers=pd.merge(papers,fmag,on=['mag_name'],how='left')\n",
    "papers.dropna(subset=[\"mag_city_code\"],inplace=True)  \n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>数据聚合</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计每个期刊包含的论文数量\n",
    "#按照期刊进行聚合\n",
    "cssci_mcount=papers.groupby(['mag_name'],as_index=False)['title'].count()\n",
    "cssci_mcount.to_csv(path+'cssci_mcount.csv',encoding='utf8',index=False)\n",
    "print(cssci_mcount)\n",
    "print(\"期刊数量：\"+str(len(cssci_mcount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照作者聚合数据\n",
    "#聚合论文等增加一个\";\",以便后面再重新展开\n",
    "path='D:/python/郭峰Python讲义/数据与结果/06数据处理/cssci/'\n",
    "f = open(path+\"cssci_org_test.csv\",encoding='utf8')\n",
    "papers= pd.read_csv(f,header=0,sep=',')\n",
    "papers['author_first']=papers['author'].str.split(';',expand=True)[0]\n",
    "\n",
    "papers['title']=papers['title'].astype('str')+\";\"\n",
    "papers['mag_name']=papers['mag_name'].astype('str')+\";\"\n",
    "print(papers.mag_name[0:10])\n",
    "group2= papers.groupby([\"author_first\"])\n",
    "author_units=pd.DataFrame(columns=[\"title\",\"mag_name\"])\n",
    "author_units['title']=group2['title'].sum()\n",
    "author_units['paper_num']=group2['title'].count()\n",
    "author_units['mag_name']=group2['mag_name'].sum()\n",
    "print(author_units.head(10))\n",
    "author_units.to_csv(path+'author_units.csv',encoding='utf8')\n",
    "f1 = open(path+\"author_units.csv\",encoding='utf8')\n",
    "author_units= pd.read_csv(f1,header=0,sep=',')\n",
    "print(\"作者聚合后样本量:\"+str(len(author_units))) #查看行*列数\n",
    "print(author_units[20:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.8：按照年份、期刊进行聚合，统计每个期刊在每一年包含的论文数量、论文总长度、平均作者人数等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Pandas高级应用2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>正则表达式</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#关键词和资助信息整理\n",
    "print(papers['keyword'][0:5])\n",
    "papers[\"keyword\"] =papers['keyword'].str.replace(\"关键词：\",\"\")\n",
    "papers[\"keyword\"] =papers['keyword'].str.replace(\"\\n\",\"\")\n",
    "papers[\"kwnum\"] =papers['keyword'].str.count(\";\")\n",
    "papers['ablength']=papers['abstract'].str.len()\n",
    "print(papers[\"fund\"][0:20])\n",
    "\n",
    "papers[\"fund\"] =papers['fund'].str.replace(\"基金：\",\"\")\n",
    "papers[\"fund01\"] =(papers['fund'].str.len()>0)\n",
    "\n",
    "papers['fund']=papers['fund'].str.replace('.*:',\"\")\n",
    "\n",
    "print(papers[\"fund\"][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers['fund']=papers['fund'].astype(str)+\";\"\n",
    "papers['fund']=papers['fund'].str.findall('\\((.*?)\\)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers[\"fund\"][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.9:提取论文基金资助课题号【学完全部内容再来处理，答案直接提供】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#答案：课题号信息提取\n",
    "import re\n",
    "papers['fund']=papers['fund'].astype(str)+\";\"\n",
    "papers['fund']=papers['fund'].str.findall('\\((.*?)\\)')  #只要括号内东西\n",
    "papers['fund']=papers[\"fund\"].map(lambda x:\";\".join(x))  #列表转字符\n",
    "papers['fund']=papers['fund'].str.replace('.*:',\"\") #“课题号：”这种情形删除 \n",
    "papers['fund']=papers['fund'].astype(str)+\";\"  \n",
    "pattern=\"[\\u4e00-\\u9fa5]+\"#中文正则表达式\n",
    "papers['fund']=papers['fund'].map(lambda x:re.sub(pattern,\"\",x)) #剔除其中中文\n",
    "papers[\"fund\"] =papers['fund'].str.replace(\"None;\",\";\")\n",
    "papers[\"fund\"] =papers['fund'].str.replace(\"nan;\",\";\")\n",
    "def fund(x):\n",
    "    x['fund']= re.split('[;，,.。？?、]',x['fund'][0:-1])  #有的存在、等分割情况\n",
    "    x['fund']=filter(lambda y: len(y)>=4, x['fund'])   #删除过短的\n",
    "    x['fund']=\";\".join(x['fund'])\n",
    "    return x['fund']\n",
    "papers['fund']=papers.apply(fund, axis=1)\n",
    "print(papers['fund'][500:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>调用函数</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >循环效率较低</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先看一个循环，将超过10页的论文，页码全部固定为10\n",
    "print(papers['page_num'][0:20])\n",
    "for i in range(0,len(papers)):\n",
    "    if papers['page_num'][i]>=10:\n",
    "        #print(i)\n",
    "        papers['page_num'][i]=10\n",
    "print(papers['page_num'][0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >这种做法，效率非常低，对于pandas形式数据的处理，要尽量避免使用循环函数。很多常规计算，都有现成的公式、方法，如上面求作者人数、标题长度等。如果没有现成的方法可以使用，则可以通过编制一个函数，然后让pandas调用这个函数，从而实现准向量化运算</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>匿名函数</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算作者发表的论文所在的期刊种类数量\n",
    "#方法1\n",
    "print(author_units[\"mag_name\"][20:40])\n",
    "author_units['mag_num']=author_units[\"mag_name\"].map(lambda x:len(set(x[0:-1].split(';'))))  \n",
    "print(author_units.mag_num[20:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>普通函数：方式1</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    mag_num=len(set(x['mag_name'][0:-1].split(';')))\n",
    "    return mag_num \n",
    "author_units['mag_num']=author_units.apply(f1, axis=1)\n",
    "print(author_units.mag_num[20:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>普通函数：方式2</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    mag_num=len(set(x[0:-1].split(';')))\n",
    "    return mag_num \n",
    "author_units['mag_num']=author_units['mag_name'].apply(f1)\n",
    "print(author_units.mag_num[20:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数的另一个应用\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "data = {'city': ['Beijing', 'Shanghai', 'Guangzhou', 'Shenzhen', 'Hangzhou', 'Chongqing'],\n",
    "       'year': [2016,2016,2015,2017,2016, 2016],\n",
    "       'population': [2100, 2300, 1000, 700, 500, 500]}\n",
    "frame = pd.DataFrame(data, columns = ['year', 'city', 'population'])\n",
    "print(frame)\n",
    "# 使用apply函数, 如果city字段包含'ing'关键词，则'判断'这一列赋值为1,否则为0\n",
    "frame['panduan'] = frame.city.apply(lambda x: 1 if 'ing' in x else 0)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.10：通过编写、调用函数的方法，在原paper数据库中生成一个新的变量，如果论文是独立作者，则为1，否则为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(papers['page_num'][0:20])\n",
    "def fn(x):\n",
    "    if x['page_num']>=10:\n",
    "        #print(i)\n",
    "        x['page_num2']=10\n",
    "    else:\n",
    "        x['page_num2']=x['page_num']\n",
    "    return x\n",
    "papers=papers.apply(fn, axis=1)\n",
    "papers[['page_num','page_num2']][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一作者作者首写字母\n",
    "import pypinyin  #汉字转拼音的一个包，需要安装\n",
    "papers[\"author_first\"]=papers[\"author_first\"].astype(str)\n",
    "papers['aufw']=papers[\"author_first\"].map(lambda x:pypinyin.pinyin(x, style=pypinyin.NORMAL)[0][0][0]) \n",
    "print(papers['author_first'][0:20])\n",
    "print(papers['aufw'][0:20])\n",
    "\n",
    "#循环的方法：非常耗时，excel表格可以计算（百度：getpy）\n",
    "#papers['index']=range(papers.shape[0])  #之前的index序号不连贯了\n",
    "#papers.set_index('index')\n",
    "#papers[\"auorder\"]=None\n",
    "#for i in range(0,len(papers)):\n",
    "#    if len(papers['author_first'])>0:\n",
    "#        papers['auorder'][i]=pypinyin.pinyin(papers['author_first'][i], style=pypinyin.NORMAL)[0][0][0]\n",
    "#    else:\n",
    "#        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习6.11：通过调用函数实现如下功能：\n",
    "#（1）在作者聚合的基础上，统计某个作者合作者数量\n",
    "#（2）在期刊*年份聚合的基础上，统计某期刊某年所有论文的平均页码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=3>数据保存</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers.shape)#查看行*列数\n",
    "papers.to_csv(path+'cssci_clean.csv',encoding='utf8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据太大，stata打不开，另保存一个只包含部分列的数据\n",
    "papers_short=papers[['mag_name','cited','download']] [0:20]\n",
    "print(papers_short.shape)#查看行*列数\n",
    "papers_short.to_csv(path+'cssci_short.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据太大，stata打不开，另保存一个只包含部分列的数据\n",
    "papers_short=papers[['mag_name','cited','download']] [0:20]\n",
    "print(papers_short.shape)#查看行*列数\n",
    "papers_short.to_csv(path+'cssci_short.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" color=blue>注意上面两个保存数据的方法，一个有index，一个没有，一般选择没有index</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录：一个完整的数据清洗代码展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先要对相关数据进行清洗，删除各种异常值、重复值等\n",
    "#使用pandas库，学习资料：http://m.sohu.com/a/158827610_693397\n",
    "#pandas里定义的数据类型： （1.）object字符值（2.）int整型（3.）float浮点型（4.）datatime时间值（5.）bool布尔值\n",
    "# pandas数据清洗参考资料：https://www.cnblogs.com/stream886/p/6021743.html\n",
    "#https://blog.csdn.net/claroja/article/details/65661826\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pypinyin\n",
    "import datetime\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "#实际工作\n",
    "'''\n",
    "path=\"D:/python/cnki/\"\n",
    "f1 = open(path+\"cssci_org1.csv\",encoding='utf8')\n",
    "papers1= pd.read_csv(f1,header=0,sep=',')\n",
    "#数据导入：https://www.cnblogs.com/OliverQin/p/8966321.html\n",
    "\n",
    "##pandas数据拼接：https://blog.csdn.net/stevenkwong/article/details/52528616\n",
    "f2 = open(path+\"cssci_org2.csv\",encoding='utf8')\n",
    "papers2= pd.read_csv(f2,header=0,sep=',')\n",
    "\n",
    "f3 = open(path+\"cssci_org3.csv\",encoding='utf8')\n",
    "papers3= pd.read_csv(f3,header=0,sep=',')   #不同电脑提取数据时方式不同，这里分隔符不同，\\t代表制表符。\n",
    "\n",
    "f4 = open(path+\"cssci_org4.csv\",encoding='utf8')\n",
    "papers4= pd.read_csv(f4,header=0,sep=',')\n",
    "\n",
    "\n",
    "f5 = open(path+\"cssci_org5.csv\",encoding='utf8')\n",
    "papers5= pd.read_csv(f5,header=0,sep=',')\n",
    "\n",
    "f6 = open(path+\"cssci_org6.csv\",encoding='utf8')  #cssci拓展版\n",
    "papers6= pd.read_csv(f6,header=0,sep=',')\n",
    "\n",
    "f7 = open(path+\"cssci_org7.csv\",encoding='utf8') #cssci拓展版\n",
    "papers7= pd.read_csv(f7,header=0,sep=',')\n",
    "\n",
    "f8 = open(path+\"cssci_org8.csv\",encoding='utf8') #cssci拓展版\n",
    "papers8= pd.read_csv(f8,header=0,sep=',')\n",
    "\n",
    "f9 = open(path+\"cssci_org9.csv\",encoding='utf8') #cssci拓展版\n",
    "papers9= pd.read_csv(f9,header=0,sep=',')\n",
    "\n",
    "f10= open(path+\"cssci_org10.csv\",encoding='utf8') #cssci拓展版\n",
    "papers10= pd.read_csv(f10,header=0,sep=',')\n",
    "\n",
    "f11= open(path+\"cssci_org11.csv\",encoding='utf8') #1998-2000\n",
    "papers11= pd.read_csv(f11,header=0,sep=',')\n",
    "\n",
    "f12= open(path+\"cssci_org12.csv\",encoding='utf8') #1998-2000\n",
    "papers12= pd.read_csv(f12,header=0,sep=',')\n",
    "\n",
    "f13= open(path+\"cssci_org13.csv\",encoding='utf8') #1998-2000\n",
    "papers13= pd.read_csv(f13,header=0,sep=',')\n",
    "\n",
    "f14= open(path+\"cssci_org14.csv\",encoding='utf8')\n",
    "papers14= pd.read_csv(f14,header=0,sep=',')\n",
    "\n",
    "f15= open(path+\"cssci_org15.csv\",encoding='utf8') \n",
    "papers15= pd.read_csv(f15,header=0,sep=',')\n",
    "\n",
    "f16= open(path+\"cssci_org16.csv\",encoding='utf8')\n",
    "papers16= pd.read_csv(f16,header=0,sep=',')\n",
    "\n",
    "f17= open(path+\"cssci_org17.csv\",encoding='utf8') \n",
    "papers17= pd.read_csv(f17,header=0,sep=',')\n",
    "\n",
    "f18= open(path+\"cssci_org18.csv\",encoding='utf8') \n",
    "papers18= pd.read_csv(f18,header=0,sep=',')\n",
    "\n",
    "f19= open(path+\"cssci_org19.csv\",encoding='utf8') \n",
    "papers19= pd.read_csv(f19,header=0,sep=',')\n",
    "\n",
    "papers= papers1.append(papers2)\n",
    "papers= papers.append(papers3)\n",
    "papers= papers.append(papers4)\n",
    "papers= papers.append(papers5)\n",
    "papers= papers.append(papers6)\n",
    "papers= papers.append(papers7)\n",
    "papers= papers.append(papers8)\n",
    "papers= papers.append(papers9)\n",
    "papers= papers.append(papers10)\n",
    "papers= papers.append(papers11)\n",
    "papers= papers.append(papers12)\n",
    "papers= papers.append(papers13)\n",
    "papers= papers.append(papers14)\n",
    "papers= papers.append(papers15)\n",
    "papers= papers.append(papers16)\n",
    "papers= papers.append(papers17)\n",
    "papers= papers.append(papers18)\n",
    "papers= papers.append(papers19)\n",
    "#papers=papers1 #如果只研究经管类，就只使用第一个数据\n",
    "#papers.drop('id',inplace=True) \n",
    "'''\n",
    "#教学演示\n",
    "path='D:/python/郭峰Python讲义/数据与结果/cssci/'\n",
    "f = open(path+\"cssci_org_test.csv\",encoding='utf8')\n",
    "papers= pd.read_csv(f,header=0,sep=',')\n",
    "\n",
    "#作为示例，输出CSV文件的前5行和最后5行，这是pandas默认的输出5行，可以根据需要自己设定输出几行的值\n",
    "#print(papers.head())\n",
    "#print(papers.tail())\n",
    "#print(papers.shape)\n",
    "\n",
    "print(\"原始爬虫数量:\"+str(len(papers))) #查看行\n",
    "\n",
    "#id没有意义，删除，删除多个变量：papers.drop(['id','title'],inplace=True) \n",
    "#凡是会对原数组作出修改并返回一个新数组的，往往都有一个 inplace可选参数。\n",
    "#如果手动设定为True（默认为False），那么原数组直接就被替换。\n",
    "#而采用inplace=False之后，原数组名对应的内存值并不改变，需要将新的结果赋给一个新的数组papers2=papers.drop('id') \n",
    "\n",
    "#删除爬虫时的重复值，以标题、期刊名和作者同时重复为准\n",
    "#删除数据参考：https://blog.csdn.net/qq_28811329/article/details/79962511\n",
    "papers.drop_duplicates(subset=['title','author','mag_name'],keep='first',inplace=True) \n",
    "print(\"删除重复爬虫后数量:\"+str(len(papers))) \n",
    "\n",
    "\n",
    "#期刊名称整理\n",
    "papers['mag_name']=papers['mag_name'].str.split('-',expand=True)[0]\n",
    "papers['mag_name']=papers['mag_name'].str.split('.',expand=True)[0]\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"(\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\")\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"（\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"）\",\"\")\n",
    "papers[\"mag_name\"] =papers['mag_name'].str.replace(\"\\n\",\"\")  #部分期刊名称存在换行的异常\n",
    "papers=papers[~papers['mag_name'].str.contains('China & World Economy')]\n",
    "papers=papers[~papers['mag_name'].str.contains('China Legal Science')]\n",
    "papers=papers[~papers['mag_name'].str.contains('湘潭大学社会科学学报研究生论丛')]\n",
    "papers=papers[~papers['mag_name'].str.contains('湘潭大学学报研究生论丛')]\n",
    "papers=papers[~papers['mag_name'].str.contains('中央民族大学学报自然科学版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('商情财经研究')]\n",
    "papers=papers[~papers['mag_name'].str.contains('科技广场管理科学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('云南经济管理干部学院学报')]\n",
    "papers=papers[~papers['mag_name'].str.contains('山东农业农村经济')]\n",
    "papers=papers[~papers['mag_name'].str.contains('中国电视纪录')]\n",
    "papers=papers[~papers['mag_name'].str.contains('公民与法法学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('China International Studies')]\n",
    "papers=papers[~papers['mag_name'].str.contains('新课程研究教育研究与实验')]\n",
    "papers=papers[~papers['mag_name'].str.contains('北京联合大学学报自然科学版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('北京联合大学学报教育教学研究专辑')]\n",
    "papers=papers[~papers['mag_name'].str.contains('山西财经大学学报高等教育版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('Chinese Journal of Library and Information Science')]\n",
    "papers=papers[~papers['mag_name'].str.contains('上海包装')]\n",
    "papers=papers[~papers['mag_name'].str.contains('药物评价研究')]\n",
    "papers=papers[~papers['mag_name'].str.contains('智能系统学报')]\n",
    "papers=papers[~papers['mag_name'].str.contains('中国战略新兴产业')]\n",
    "papers=papers[~papers['mag_name'].str.contains('吉林大学学报工学版')]\n",
    "papers=papers[~papers['mag_name'].str.contains('商丘职业技术学院学报')]\n",
    "papers=papers[~papers['mag_name'].str.contains('食品科学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('玉米科学')]\n",
    "papers=papers[~papers['mag_name'].str.contains('电脑知识与技术学术交流')]\n",
    "\n",
    "\n",
    "#不规范期刊名称替换\n",
    "fmag_name= open(path+\"mag_name_adj.csv\",encoding='utf8')\n",
    "mag_name= pd.read_csv(fmag_name,header=0,sep=',')\n",
    "for i in range(0,len(mag_name)):\n",
    "    papers[\"mag_name\"] =papers['mag_name'].str.replace(str(mag_name.mag_name_ord[i]),str(mag_name.mag_name_new[i]))  \n",
    "\n",
    "#期刊名称修改后，再删除一下可能的重复值\n",
    "papers.drop_duplicates(subset=['title','author','mag_name'],keep='first',inplace=True) \n",
    "print(\"期刊异常剔除后数量:\"+str(len(papers))) #查看行*列数\n",
    "\n",
    "#输出样本期刊列表\n",
    "cssci_mcount=papers.groupby(['mag_name'],as_index=False)['title'].count()\n",
    "cssci_mcount.to_csv(path+'cssci_mcount.csv',encoding='utf8',index=False)\n",
    "print(\"期刊数量：\"+str(len(cssci_mcount)))\n",
    "\n",
    "#删除论文标题为空的样本\n",
    "#删除数据的几种情况：https://www.cnblogs.com/cocowool/p/8421997.html\n",
    "papers.dropna(subset=[\"title\"],inplace=True)  #删除作者为空的样本\n",
    "#删除空值的另一种方式，将df中A列所有空值赋值为'null'，然后再删除\n",
    "#papers['author']=papers['author'].fillna('null') \n",
    "#papers=papers[~papers['author'].isin(['null'])]\n",
    "\n",
    "#删除非论文文章：删除标题中还有以下字段的数据\n",
    "papers=papers[~papers['title'].str.contains('卷首语')]\n",
    "papers=papers[~papers['title'].str.contains('寄语')]\n",
    "papers=papers[~papers['title'].str.contains('发刊词')]\n",
    "papers=papers[~papers['title'].str.contains('序言')]\n",
    "papers=papers[~papers['title'].str.contains('简讯')]\n",
    "papers=papers[~papers['title'].str.contains('会讯')]\n",
    "papers=papers[~papers['title'].str.contains('会议简述')]\n",
    "papers=papers[~papers['title'].str.contains('会议综述')]\n",
    "papers=papers[~papers['title'].str.contains('会议纪实')]\n",
    "papers=papers[~papers['title'].str.contains('研讨会')]\n",
    "papers=papers[~papers['title'].str.contains('名单')]\n",
    "papers=papers[~papers['title'].str.contains('纪要')]\n",
    "papers=papers[~papers['title'].str.contains('诞辰')]\n",
    "papers=papers[~papers['title'].str.contains('悼词')]\n",
    "papers=papers[~papers['title'].str.contains('评奖')]\n",
    "papers=papers[~papers['title'].str.contains('目录')]\n",
    "papers=papers[~papers['title'].str.contains('启事')]\n",
    "papers=papers[~papers['title'].str.contains('广告')]\n",
    "papers=papers[~papers['title'].str.contains('公告')]\n",
    "\n",
    "#删除标题异常样本\n",
    "papers[\"tlength\"]=papers['title'].str.len()  #标题长度，不能是papers[\"tlength\"]=len(papers['title'])\n",
    "papers=papers[papers['tlength'] <100]  #删除标题长度大于100的异常值\n",
    "papers=papers[papers['tlength'] >2]  #删除标题长度小于2的异常值\n",
    "print(\"标题剔除后数量:\"+str(len(papers))) \n",
    "\n",
    "#删除长度异常样本\n",
    "#papers=papers[(papers['page_num'] >0) & (papers['page_num'] <100)]\n",
    "print(\"页码异常剔除后数量:\"+str(len(papers))) \n",
    "#其他padas运算：https://www.jianshu.com/p/805f20ac6e06\n",
    "\n",
    "#删除作者异常样本\n",
    "papers.dropna(subset=[\"author\"],inplace=True)  #删除作者为空的样本\n",
    "papers=papers[~papers['author'].str.contains('编辑部')]   #删除作者信息中包含“编辑部”的样本。\n",
    "papers[\"aunum\"] =papers['author'].str.count(\";\")+1\n",
    "papers=papers[papers['aunum'] <20]    #删除作者数量大于等于20的样本\n",
    "print(\"作者异常剔除后数量:\"+str(len(papers))) #查看行*列数\n",
    "\n",
    "#第一作者识别，这个涉及到pandas分列\n",
    "papers['author_first']=papers['author'].str.split(';',expand=True)[0]\n",
    "\n",
    "#第一作者作者首写字母,一个个循环，非常耗时，excel表格可以计算（百度：getpy）\n",
    "papers['aufw']=papers[\"author_first\"].map(lambda x:pypinyin.pinyin(x, style=pypinyin.NORMAL)[0][0][0]) \n",
    "\n",
    "#papers['index']=range(papers.shape[0])  #之前的index序号不连贯了\n",
    "#papers.set_index('index')\n",
    "#papers[\"auorder\"]=None\n",
    "#for i in range(0,len(papers)):\n",
    "#    if len(papers['author_first'])>0:\n",
    "#        papers['auorder'][i]=pypinyin.pinyin(papers['author_first'][i], style=pypinyin.NORMAL)[0][0][0]\n",
    "#    else:\n",
    "#        pass\n",
    "\n",
    "\n",
    "#关键词和资助信息整理\n",
    "papers[\"keyword\"] =papers['keyword'].str.replace(\"关键词：\",\"\")\n",
    "papers[\"keyword\"] =papers['keyword'].str.replace(\"\\n\",\"\")\n",
    "papers[\"kwnum\"] =papers['keyword'].str.count(\";\")\n",
    "papers['ablength']=papers['abstract'].str.len()\n",
    "papers[\"fund\"] =papers['fund'].str.replace(\"基金：\",\"\")\n",
    "papers[\"fund01\"] =(papers['fund'].str.len()>0)\n",
    "papers[\"fundn\"]=((papers['fund'].str.contains('国家社科'))|(papers['fund'].str.contains('国家自科'))|(papers['fund'].str.contains('国家社会科学'))|(papers['fund'].str.contains('国家自然科学')))\n",
    "papers['fund']=papers['fund'].astype(str)+\";\"\n",
    "papers['fund']=papers['fund'].str.findall('\\((.*?)\\)')\n",
    "papers['fund']=papers[\"fund\"].map(lambda x:\",\".join(x))  \n",
    "papers['fund']=papers['fund'].str.replace('.*:',\"\")\n",
    "\n",
    "#期刊-主办单位匹配\n",
    "#pandas merge方法：https://blog.csdn.net/Darkman_EX/article/details/80726166\n",
    "fmag= open(path+\"mag_unit.csv\",encoding='utf8')\n",
    "fmag= pd.read_csv(fmag,header=0,sep=',')\n",
    "papers=pd.merge(papers,fmag,how='left')\n",
    "papers.dropna(subset=[\"mag_city_code\"],inplace=True)  \n",
    "\n",
    "#发表时间整理\n",
    "papers['year_period']=papers['year_period'].str[0:10]  #部分样本存在“2017-12-15 14：55”这样的year_period\n",
    "#papers['year_period']=papers['year_period'][0:10]  #如果是这样，则代表只要这个变量的前10行。。。\n",
    "print(papers['year_period'].tail())\n",
    "papers['year']=papers['year_period'].str[0:4]\n",
    "papers['month']=papers['year_period'].str[5:7]\n",
    "papers['month']=papers['month'].str.extract('(\\d+)', expand=False)\n",
    "#部分日期格式存在问题，正常为2017-06-15，部分样本为2017/6/15,上式将数字“/6\"当中的数字提取出来\n",
    "#pandas字符中提取数字：https://blog.csdn.net/PeersLee/article/details/77948423   \n",
    "#示例：df[['室', '厅', '厨', '卫']] = df['户型'].str.extract('(\\d+)室(\\d+)厅(\\d+)厨(\\d+)卫', expand=False)\n",
    "papers=papers[papers['year'].str.len()>0]  #部分样本日期存在错误\n",
    "#年和月数据都转换成整数\n",
    "papers['year']=papers['year'].astype(\"int\")\n",
    "papers['month']=papers['month'].astype(\"int\")\n",
    "#以下语法对部分样本可用，现在全样本存在错误，日期格式存在非法字符\n",
    "#papers['date_time'] = pd.to_datetime(papers['year_period'])\n",
    "#papers['year']=papers['date_time'].dt.year\n",
    "#papers['month']=papers['date_time'].dt.month\n",
    "papers=papers[papers[\"year\"]<2019]\n",
    "papers=papers[papers[\"year\"]>1997]  \n",
    "\n",
    "#发表日期精确到月\n",
    "papers['ym']=papers['year'].astype('str')+'-'+papers['month'].astype('str')+'-'+'01'\n",
    "papers['ym']=pd.to_datetime(papers['ym']) \n",
    "#papers['year_period']=pd.to_datetime(papers['year_period']) #日期中存在非法字符，这个日期会报错\n",
    "print(papers['ym'][0:5])\n",
    "\n",
    "print(\"年份异常剔除后数量:\"+str(len(papers))) #查看行*列数1541039\n",
    "\n",
    "#起始页码处理和论文卷期内排序\n",
    "papers['page_beg']=papers['page_range'].str.split('-',expand=True)[0]\n",
    "papers['page_beg']=papers['page_beg'].str.split('+',expand=True)[0]\n",
    "print(papers.shape)#查看行*列数\n",
    "#page_beg存在4万个空值，暂不计算论文排序了，ps:stata计算排序要简单的多\n",
    "#papers=papers[papers[\"page_beg\"].astype('int')<10000] #存在一个异常起始页456789\n",
    "#papers['mag_period']=papers['mag_name']+papers['year_period']\n",
    "#papers['page_sort']=papers['page_beg'].groupby(papers['mag_period']).rank(ascending=0,method='dense')\n",
    "#data['group_sort']=data['comment_num'].groupby(data['cate']).rank(ascending=0,method='dense')\n",
    "#papers['abstract']=papers['abstract'].fillna('null') #将df中A列所有空值赋值为'null'\n",
    "\n",
    "##分类号处理，只保留第一个字母\n",
    "papers[\"class_num\"] =papers['class_num'].str.replace(\"分类号：\",\"\")\n",
    "papers['class_num']=papers['class_num'].str.replace('(\\d+)',\"\") \n",
    "papers['class_num']=papers['class_num'].str.replace('.',\"\") \n",
    "papers['class_num']=papers['class_num'].str.replace('+',\"\")\n",
    "papers['class_num']=papers['class_num'].str.replace('-',\"\")\n",
    "\n",
    "#合作者提取，只以第一个“；”来分割，并保留第二个，从而得到第一作者之外的所有合作者\n",
    "papers['coauthor']=papers['author'].str.split(';',n=1,expand=True)[1]  \n",
    "\n",
    "#对学科分类进行重新调整，经济类和管理类合并，高校学报和综合社会科学合并\n",
    "papers['mag_classn']=papers[\"mag_class\"]\n",
    "papers['mag_classn']=papers[\"mag_classn\"].str.replace(\"经济学\",\"经济与管理\")\n",
    "papers['mag_classn']=papers[\"mag_classn\"].str.replace(\"管理学\",\"经济与管理\")\n",
    "papers['mag_classn']=papers[\"mag_classn\"].str.replace(\"统计学\",\"经济与管理\")\n",
    "papers['mag_classn']=papers[\"mag_classn\"].str.replace(\"高校学报\",\"综合社会科学\")\n",
    "\n",
    "print(papers.shape)#查看行*列数\n",
    "papers.to_csv(path+'cssci_clean.csv',encoding='utf8')\n",
    "\n",
    "#数据保存\n",
    "#计算主题模型时，需要将标题、关键词和摘要合并\n",
    "#papers['keyword']=papers['keyword'].fillna(\";\")\n",
    "#papers['content']=papers['title']+\";\"+papers['keyword']+\";\"+papers['abstract']\n",
    "#papers=papers[papers['content'].str.len()>100]   #将标题+关键词+摘要少于100字的样本删除\n",
    "#print(\"标题+关键词+摘要少于100字的样本删除后数量:\"+str(len(papers))) #查看行*列数\n",
    "#print(papers.shape)#查看行*列数\n",
    "#papers.to_csv(path+'cssci_abstract_clean.csv',encoding='utf8')\n",
    "\n",
    "#数据太大，stata打不开，另保存一个只包含部分列的数据\n",
    "papers_short=papers[['tlength','mag_name','mag_city_code','guanxi_drop','aunum','author_first','aufw','cited','download','fund01','fundn','page_num','year_period','year','month','kwnum','ablength','page_beg']] \n",
    "print(papers_short.shape)#查看行*列数\n",
    "papers_short.to_csv(path+'cssci_short.csv',encoding='utf8')\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime - starttime).seconds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
