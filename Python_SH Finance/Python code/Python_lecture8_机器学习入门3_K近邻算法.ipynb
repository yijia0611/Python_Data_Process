{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8讲 机器学习入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >郭峰（Email：guofengsfi@163.com)   \n",
    "副教授、博士生导师  \n",
    "上海财经大学公共经济与管理学院 </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >本讲目录：  \n",
    "8.1. 机器学习原理  \n",
    "8.2. 线性回归、岭回归和Lasso回归  \n",
    "8.3. K近邻算法  \n",
    "8.4. 朴素贝叶斯算法  \n",
    "8.5. 机器学习实操案例</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3. K近邻算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >在近邻分类算法中，对于预测的数据，将其与训练样本进行比较，找到最为相似的K个训练样本，并以这K个训练样本中出现最多的标签作为最终的预测标签。在近邻分类算法中，最主要的是K-近邻算法。</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据演示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >目标：以鸢尾花分类为示例，介绍KNN算法，鸢尾花可以被分为setosa、versicolor、virginica三个品种，现在我们要建立一个模型，输入新的叶子数据判定它是属于哪一类。原理就是看新的叶子数据跟已知三个品众那个长得最像。</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "Y:\n",
      " [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data   #x展示了样本的四个特征，根据这四个特征，预测花的品种\n",
    "print('X:\\n',X[0:10])\n",
    "Y=iris.target\n",
    "print('Y:\\n',Y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >我们使用欧氏距离公式，计算两个向量点之间的距离;计算完所有点之间的距离后，可以对数据按照从小到大的次序排序;统计距离最近前k个数据点的类别数，返回票数最多的那类类别。</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将训练集和测试集进行划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >导入的数据集我们要分为训练集和测试集，一般都是采用3：1的随机分配办法； \n",
    "而拆分时为了数据分布均匀，我们先要对数据进行随机达伦，确保测试数据和训练数据的全面性；\n",
    "在scikit-learn中，我们可以调用train_test_split函数实现划分，利用random_state指定随机数生成种子即可。</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn中的train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对模型的正确率进行衡量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#方法1\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "iris=datasets.load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "\n",
    "knn_classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(x_train,y_train)    #因为knn对算法进行了封装，既包括构建模型的算法，也包括预测的算法，我们只需要调用fit方法来训练数据即可。\n",
    "y_predict=knn_classifier.predict(x_test)\n",
    "scores=knn_classifier.score(x_test,y_test)\n",
    "print('acc:{}'.format(sum(y_predict==y_test)/len(y_test)),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Predicted target name:['setosa']\n"
     ]
    }
   ],
   "source": [
    "#直接使用sklean自带的程序，预测某一个点的分类结果\n",
    "X_new = np.array([[5,2.9,1,0.2]])\n",
    "prediction =knn_classifier.predict(X_new)\n",
    "print(prediction)\n",
    "print(\"Predicted target name:{}\".format(iris['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最好的k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >得到正确率之后，想要进一步的提升在测试集上的正确率，我们就需要对模型进行调参;\n",
    "超参数：在算法运行前需要设定的参数（通过领域知识、经验数值、实验搜索来寻找好的超参数）,KNN算法中的k是典型的超参数，我们将采用实验搜索来寻找好的超参数，例如在k=1到10之间一个个测试，看那个k效果最好</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.98\n",
      "2 0.9844444444444445\n",
      "3 0.9866666666666667\n",
      "4 0.9844444444444445\n",
      "5 0.9866666666666667\n",
      "6 0.9866666666666667\n",
      "7 0.9822222222222222\n",
      "8 0.9822222222222222\n",
      "9 0.98\n",
      "最好的k为:3,最好的得分为:0.9867\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "digits=datasets.load_digits()\n",
    "x=digits.data\n",
    "y=digits.target\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=666)\n",
    "\n",
    "# 寻找最好的k\n",
    "best_k=-1\n",
    "best_score=0\n",
    "for i in range(1,10):\n",
    "    knn_clf=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_clf.fit(x_train,y_train)\n",
    "    scores=knn_clf.score(x_test,y_test)\n",
    "    print(i,scores)\n",
    "    if scores>best_score:\n",
    "        best_score=scores\n",
    "        best_k=i\n",
    "print('最好的k为:%d,最好的得分为:%.4f'%(best_k,best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在sklearn中，可以通过\"网格搜索\"，自动寻找最优参数，具体做法可以参考网络资料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最好的k为:3,最好的得分为:0.9867,最好的方法uniform\n"
     ]
    }
   ],
   "source": [
    "#寻找最优超参数weights\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "digits=datasets.load_digits()\n",
    "x=digits.data\n",
    "y=digits.target\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=666)\n",
    "\n",
    "# 寻找最好的k,weights\n",
    "best_k=-1\n",
    "best_score=0\n",
    "best_method=''\n",
    "for method in ['uniform','distance']:\n",
    "    for i in range(1,11):\n",
    "        knn_clf=KNeighborsClassifier(n_neighbors=i,weights=method)\n",
    "        knn_clf.fit(x_train,y_train)\n",
    "        scores=knn_clf.score(x_test,y_test)\n",
    "        if scores>best_score:\n",
    "            best_score=scores\n",
    "            best_k=i\n",
    "            best_method=method\n",
    "print('最好的k为:%d,最好的得分为:%.4f,最好的方法%s'%(best_k,best_score,best_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实战案例：手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "path='D:/python/郭峰Python讲义/数据与结果/08机器学习入门/'\n",
    "Image(filename = path+'num_data.png', width=500, height=260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#步骤1：导入第三方库\n",
    "from numpy import *\n",
    "import os\n",
    "from os import listdir\n",
    "import operator\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#步骤2：路径与标签\n",
    "path1='D:/python/郭峰Python讲义/数据与结果/08机器学习入门/digits/trainingDigits/'\n",
    "path2='D:/python/郭峰Python讲义/数据与结果/08机器学习入门/digits/testDigits/'\n",
    "print(path1)\n",
    "#将训练数据存储到一个矩阵中1024维，并存储对应的标签\n",
    "trainName=listdir(path1)\n",
    "trainNum=len(trainName)\n",
    "trainNumpy = zeros((trainNum,1024))\n",
    "#print(\"trainNum=%d\"%trainNum)\n",
    "#对文件名进行分析，训练文本对应的标签\n",
    "print(trainNum)\n",
    "print(trainName[0])\n",
    "\n",
    "\n",
    "#将测试数据存储到一个矩阵中1024维，并存储对应的标签\n",
    "testName=listdir(path2)\n",
    "testNum=len(testName)\n",
    "testNumpy = zeros((testNum,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#步骤3：将像素数据转换成向量数据\n",
    "#这个函数是1024长度的向量\n",
    "def img2vector(filename):\n",
    "    vect=zeros((1,1024))\n",
    "    f=open(filename)\n",
    "    for i in range(32):\n",
    "        line=f.readline()\n",
    "        for j in range(32):\n",
    "            vect[0,32*i+j]=int(line[j])\n",
    "    return vect\n",
    "handlabel=[]\n",
    "\n",
    "#训练集\n",
    "for i in range(trainNum):\n",
    "    filename=trainName[i]#文件名\n",
    "    filestr=filename.split('.')[0]#不带后缀的文件名\n",
    "    filelabel=int(filestr.split('_')[0])#文件的标签,0,1,2,....,9\n",
    "    #将标签添加至handlabel中\n",
    "    handlabel.append(filelabel)\n",
    "    trainNumpy[i,:]=img2vector(path1+str(filename))#转成1024\n",
    "    #print(handlabel[:20])\n",
    "\n",
    "print(trainNumpy[0][0:40])\n",
    "print(trainNumpy.shape[0])\n",
    "print(handlabel[0:40])\n",
    "print(len(handlabel))\n",
    "\n",
    "#测试集\n",
    "handlabel_test=[]\n",
    "for i in range(testNum):\n",
    "    filename_test=testName[i]#文件名\n",
    "    filestr_test=filename_test.split('.')[0]#不带后缀的文件名\n",
    "    filelabel_test=int(filestr_test.split('_')[0])#文件的标签,0,1,2,....,9\n",
    "    #将标签添加至handlabel中\n",
    "    handlabel_test.append(filelabel_test)\n",
    "    testNumpy[i,:]=img2vector(path1+str(filename_test))#转成1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=handlabel\n",
    "x_train=trainNumpy  #列表，1934个元素，每个元素又是一个1024长度的列表\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "\n",
    "print(y_train[0:20])\n",
    "print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=handlabel_test\n",
    "x_test=testNumpy  #列表，1934个元素，每个元素又是一个1024长度的列表\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#步骤四：定义KNN算法，并进行测试\n",
    "knn_classifier=KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(x_train,y_train)    \n",
    "y_predict=knn_classifier.predict(x_test)\n",
    "scores=knn_classifier.score(x_test,y_test)\n",
    "print('acc:{}'.format(sum(y_predict==y_test)/len(x_test)),scores)\n",
    "print(y_predict[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"宋体\" >机器学习实操中，工作量主要体现在如何对一个图片、文字进行数量化表达(特征工程)。上述关于图片的向量化表达是一个信息损失很大的方式，更好的特征工程方法需要运用到图像处理、深度学习等知识，超出了本课程的范围。</font> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
